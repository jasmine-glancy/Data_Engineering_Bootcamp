# <img src="../books.svg" alt="Stack of red books with a graduation cap on top, symbolizing education and achievement, set against a plain background" width="30" height="20" /> Data Pipeline Maintenance

## <img src="../notes.svg" alt="Orange pencil lying diagonally on a white sheet of paper, representing note taking and documentation, with a clean and organized appearance" width="20" height="15" /> Navigating the Complexities of Data Engineering Day 1 Lecture

| Concept                | Notes            |
|---------------------|------------------|
| **Difficult Parts of Data Engineering**  | <br>- Data engineering isn't just writing SQL and sipping martinis on a beach! <br> &emsp;•  High expectations<br> &emsp;&emsp;• Building pipelines is a **marathon**<br> &emsp;&emsp;• Analytics is a **sprint**<br> &emsp;&emsp;• ***Say no to sprinting the marathon***<br> &emsp;&emsp;&emsp;• Every time you cut corners, you will pay for it later<br> &emsp;• 90%+ of data engineers are experiencing burnout right now<br> &emsp;• Protect your peace, and you will last longer<br>- Data quality issues<br>- Every time you build a pipeline, you have to maintain it <br> &emsp;• There is a continual cost that adds up over time <br>- Unclear priorities/ ad hoc requests|
| **Ad Hoc Requests**  | - Analytics need to solve an **URGENT** problem <br> &emsp;• If everything is urgent, nothing is<br>- Allocate ~5-10% per quarter to ad hoc requests<br> &emsp;• Half a day a week <br> &emsp;• If the request is ad hoc and complex, you shouldn't drop what you are doing <br> &emsp;• Low hanging fruit can be prioritized, though!<br> &emsp;• Consider ROI- if they are asking for a project, put it on the road map<br>- Get analytics partners input for quarterly planning so ad hoc requests become scalable models<br> &emsp;• Plan stuff out! It helps! :) |
| **Ownership Models**  | - Who owns what? <br> &emsp;• Data sets<br> &emsp;• Data pipeline <br> &emsp;• Data documentation <br> &emsp;• Metrics <br> &emsp;• Experiments <br><br>- ***The most common ownership model:*** <br> &emsp;• **Primary software engineer ownership** <br> &emsp;&emsp;• Logging/exports<br> &emsp;• **Primary data engineer ownership** <br> &emsp;&emsp;• Pipeline <br> &emsp;&emsp;• Master data<br> &emsp;• **Primary data analyst/scientist ownership** <br> &emsp;&emsp;• Metrics or Aggregate Master Data<br> &emsp;&emsp;• Dashboards/Experiments<br> &emsp;• Overlap in ownership exists as well when needed <br> &emsp;• Business questions are related to metrics usually <br><br>- ***Another common ownership model:*** <br> &emsp;• **Primary software engineer ownership** <br> &emsp;&emsp;• Logging/exports<br> &emsp;• **Primary analytics engineer ownership** <br> &emsp;&emsp;• Pipeline <br> &emsp;&emsp;• Master data<br> &emsp;&emsp;• Metrics or Aggregate Master Data<br> &emsp;• **Primary data analyst/scientist ownership** <br> &emsp;&emsp;• Dashboards/Experiments<br> &emsp;• Overlap in ownership exists as well when needed <br> &emsp;• Business questions are related to metrics usually |
| **Common Ownership Problems**  | - Arise at the boundaries <br> &emsp;• Data engineers owning logging or metrics <br> &emsp;• Data scientists writing pipelines <br>- Going too deep into someone else's box can burn you out faster <br> &emsp;• Work *together* <br> &emsp;• There should be a secondary person in case someone takes time off |
| **Centralized vs Embedded Teams**  | - ***Centralized*** <br> &emsp;• Many data engineers in one team<br> &emsp;• On call is easier <br> &emsp;&emsp;• Regarding on call, it is good to discuss the potential consequences of not being able to address outages at odd hours<br> &emsp;• Knowledge sharing, data engineers supporting data engineers<br> &emsp;• Expensive!<br> &emsp;• Prioritization can get complex <br><br>- ***Embedded***<br> &emsp;• Data engineers in other engineering teams <br> &emsp;• Dedicated DE support<br> &emsp;• Data engineer gains deep domain knowledge<br> &emsp;• Islands of responsibility <br> &emsp;• Data engineers can feel isolated|
| **Common Pipeline Issues**  | - Skewed pipelines with Out of Memory exceptions<br>- Missing data/schema change of upstream data<br>- Backfill needs to trigger downstream data sets <br>-Business questionsabout where and how to use data |
| **How to Fix Skew**  | - Best option <br> &emsp;• **Upgrade to Spark 3**  and enable adaptive execution!<br>- Second best option <br> &emsp;• Bump up the executor memory and hope it's not more skewed later<br>- Third best option <br> &emsp;• Update the job to include a skew join salt |
| **Fixing Missing Data / Schema Change**  | - Pre-check your upstream data! <br> &emsp;• This will prevent your pipeline from running if it's missing data!<br>- Track down the upstream owner <br> &emsp;• Fill out a task/ticket/etc to have them fix the issue<br> &emsp;&emsp;• Both unblock and long-term fix |
| **Good Data Migrations**  | ![Backfill](backfill.png)- How backfills work <br> &emsp;• **For small migrations** <br> &emsp;&emsp;• Do a parallel backfill into `table_backfill`<br> &emsp;&emsp;• If everything looks good, do the "shell game"<br> &emsp;&emsp;&emsp;• Rename `production` to `production_old`<br> &emsp;&emsp;&emsp;• Rename `table_backfill` to `production`<br> &emsp;• **If people need a lot more time migrate (a lot more painful)**<br> &emsp;&emsp;• Build a paralell pipeline that populates `table_v2` while `production` gets migrated<br> &emsp;&emsp;• After all references to `production` have been updated, drop production and rename table_v2 (and all its references) to `production` <br>- Let downstream engineers know when you rename columns in case they are working with them|
| **Business Questions**  | - Set expectations on when you'll get back to people. Maybe it's 2 hours, maybe it's a day? <br> - Consolidate common questions into a document so you don't have to keep answering the same questions over and over again <br>- Is this the same or differnt oncall from the pipeline oncall?<br>- Make sure your analytics partners are looped in, here! |

## <img src="../question-and-answer.svg" alt="Two speech bubbles, one with a large letter Q and the other with a large letter A, representing a question and answer exchange in a friendly and approachable style" width="35" height="28" /> Cues

- What is a common consequence of having too many data pipelines as a data engineer?
- Why is data engineering often considered to have high expectations leading to burnout?
- What is typically the most important part of properly handling ad hoc requests in data engineering?
- In what way is building data pipelines compared to historical infrastructure projects?
- How can data engineers reduce potential burnout caused by on-call duties?

---

## <img src="../summary.svg" alt="Rolled parchment scroll with visible lines, symbolizing a summary or conclusion, placed on a neutral background" width="30" height="18" /> Summary

As more pipelines are created, the likelihood of failure increases. This requires more on-call responses, increasing maintenance costs and leading to potential burnout. High expectations stem from dealing with unclear priorities and persistent data quality issues, which contribute to stress and burnout. It's important to prioritize requests based on their return on investiment. This ensures complex requests are strategically placed into the roadmap rather than rushed.

Understanding the exact impact helps prioritize and manage tasks better, which reduces unnecessary stress and burnout. Just as sustainable infrastructure supports long-term use, data pipelines should be carefully constructed to ensure quality and maintainability over time.
